{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMzuSPGyYf3oaQwOI1YlqH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fab311111/Fab/blob/main/attrition_prediction_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZZc6gy4Z7t6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c874b35c",
        "outputId": "09e9e59d-a910-46d9-9fed-da67814f921f"
      },
      "source": [
        "# app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Set Streamlit page configuration\n",
        "st.set_page_config(page_title=\"Employee Attrition Prediction\", layout=\"centered\")\n",
        "\n",
        "# Load the trained model and scaler\n",
        "best_rf_model = None\n",
        "scaler = None\n",
        "df_original = None\n",
        "expected_feature_columns = None\n",
        "\n",
        "try:\n",
        "    best_rf_model = joblib.load('best_rf_model.joblib')\n",
        "    scaler = joblib.load('scaler.joblib')\n",
        "\n",
        "    # Load the original dataset to retrieve employee data by ID\n",
        "    df_original = pd.read_csv(\"WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n",
        "\n",
        "    # Assuming the original training columns are needed for consistent feature ordering\n",
        "    # This would ideally be saved during training or derived from the original data loading/preprocessing\n",
        "    # For now, let's derive the expected feature columns based on the preprocessing steps in the notebook.\n",
        "\n",
        "    # Drop irrelevant/constant columns as done in the notebook\n",
        "    columns_to_drop_for_template = [\n",
        "        'EmployeeCount', 'StandardHours', 'Over18', 'EmployeeNumber'\n",
        "    ]\n",
        "    # Create a temporary copy to avoid modifying df_original before retrieving data by ID\n",
        "    temp_df_for_columns = df_original.drop(columns=columns_to_drop_for_template).copy()\n",
        "\n",
        "    # Identify original numerical and categorical columns\n",
        "    original_categorical_cols = temp_df_for_columns.select_dtypes(include=['object']).columns\n",
        "    original_numerical_cols = temp_df_for_columns.select_dtypes(include=[np.number]).columns.drop('Attrition')\n",
        "\n",
        "    # Perform one-hot encoding on a temporary dataframe to get the list of expected feature columns\n",
        "    # This ensures the order matches the training data\n",
        "    temp_df_for_columns = pd.get_dummies(temp_df_for_columns.drop('Attrition', axis=1), columns=original_categorical_cols, drop_first=True)\n",
        "    expected_feature_columns = temp_df_for_columns.columns.tolist()\n",
        "\n",
        "\n",
        "    st.success(\"Model, scaler, and original data loaded successfully.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    st.error(\"Error: Model, scaler, or original data file not found. Please ensure 'best_rf_model.joblib', 'scaler.joblib', and 'WA_Fn-UseC_-HR-Employee-Attrition.csv' are in the correct directory.\")\n",
        "    st.stop() # Stop the app if essential files are missing\n",
        "except Exception as e:\n",
        "    st.error(f\"An error occurred during loading: {e}\")\n",
        "    st.stop() # Stop the app if any other loading error occurs\n",
        "\n",
        "\n",
        "# Add a title and a brief description for the application\n",
        "st.title('Employee Attrition Prediction')\n",
        "st.write(\"\"\"\n",
        "This application predicts the likelihood of an employee leaving the company based on their characteristics.\n",
        "Please enter the employee number to get their predicted attrition risk and potential intervention areas.\n",
        "\"\"\")\n",
        "\n",
        "# Add a header for the input section\n",
        "st.header('Enter Employee Information')\n",
        "\n",
        "# Add a numerical input field for the \"Employee Number\"\n",
        "if df_original is not None:\n",
        "    employee_number_input = st.number_input(\n",
        "        'Employee Number',\n",
        "        min_value=int(df_original['EmployeeNumber'].min()), # Set minimum to the smallest employee number\n",
        "        max_value=int(df_original['EmployeeNumber'].max()), # Set maximum to the largest employee number\n",
        "        value=int(df_original['EmployeeNumber'].min()), # Default to the smallest employee number\n",
        "        step=1\n",
        "    )\n",
        "else:\n",
        "    st.warning(\"Could not load original data to set employee number range.\")\n",
        "    employee_number_input = st.number_input(\n",
        "        'Employee Number',\n",
        "        min_value=1, # Set minimum to a default value\n",
        "        max_value=10000, # Set maximum to a default value\n",
        "        value=1, # Default to a default value\n",
        "        step=1\n",
        "    )\n",
        "\n",
        "\n",
        "# Function to retrieve and prepare input data for prediction based on Employee Number\n",
        "def prepare_input_data_by_id(employee_id, df_original, scaler, original_numerical_cols, original_categorical_cols, expected_columns):\n",
        "    # Retrieve the row for the given EmployeeNumber\n",
        "    employee_data = df_original[df_original['EmployeeNumber'] == employee_id].copy()\n",
        "\n",
        "    # Check if an employee with the given ID exists\n",
        "    if employee_data.empty:\n",
        "        return None, \"Employee Number not found in the dataset.\", None\n",
        "\n",
        "    # Store original data for intervention suggestions later\n",
        "    original_employee_data = employee_data.iloc[0].copy()\n",
        "\n",
        "    # Drop irrelevant columns as done during training\n",
        "    columns_to_drop = [\n",
        "        'EmployeeCount', 'StandardHours', 'Over18', 'EmployeeNumber', 'Attrition' # Also drop Attrition as it's the target\n",
        "    ]\n",
        "    employee_data_processed = employee_data.drop(columns=columns_to_drop)\n",
        "\n",
        "    # Apply one-hot encoding to the employee data\n",
        "    # Ensure all possible dummy columns are created, even if not present in this single row\n",
        "    # A robust way is to create a template DataFrame with all expected columns and fill with 0\n",
        "    input_df = pd.DataFrame(columns=expected_columns)\n",
        "    input_df.loc[0] = 0 # Initialize with zeros\n",
        "\n",
        "    # Fill in the numerical values from the employee data\n",
        "    for col in original_numerical_cols:\n",
        "        if col in employee_data_processed.columns:\n",
        "             input_df.loc[0, col] = employee_data_processed.iloc[0][col]\n",
        "\n",
        "\n",
        "    # Fill in the one-hot encoded categorical values\n",
        "    # This requires knowing the exact column names created by get_dummies with drop_first=True\n",
        "    # A more robust way is to save the list of columns from X_train or the one-hot encoder itself.\n",
        "    # For this implementation, we reconstruct based on original columns and expected dummy column names.\n",
        "    for col in original_categorical_cols:\n",
        "        if col in employee_data_processed.columns:\n",
        "            category_value = employee_data_processed.iloc[0][col]\n",
        "            dummy_col_name = f'{col}_{category_value}'\n",
        "            # Check if this specific dummy column name is in our expected columns (due to drop_first=True)\n",
        "            if dummy_col_name in expected_columns:\n",
        "                 input_df.loc[0, dummy_col_name] = 1\n",
        "\n",
        "    # Ensure the columns are in the correct order\n",
        "    input_df = input_df[expected_columns]\n",
        "\n",
        "\n",
        "    # Scale numerical features using the loaded scaler\n",
        "    # Identify numerical columns in the input_df based on the original numerical columns list\n",
        "    numerical_cols_in_input = original_numerical_cols[original_numerical_cols.isin(input_df.columns)]\n",
        "    input_df[numerical_cols_in_input] = scaler.transform(input_df[numerical_cols_in_input])\n",
        "\n",
        "\n",
        "    # Return the preprocessed data and original data\n",
        "    return input_df, original_employee_data, None # Return the prepared DataFrame, original data, and no error message\n",
        "\n",
        "# Function to suggest intervention areas based on employee data\n",
        "# This function now correctly uses the original employee data Series\n",
        "def suggest_interventions(employee_data, df_original):\n",
        "    interventions = []\n",
        "\n",
        "    # Example intervention suggestions based on key features from earlier analysis and general risk factors\n",
        "    # Access values using employee_data (the original Series for the employee)\n",
        "    # Added checks for column existence for robustness\n",
        "\n",
        "    # Lower MonthlyIncome might be a risk factor\n",
        "    if 'MonthlyIncome' in employee_data and 'MonthlyIncome' in df_original.columns and employee_data['MonthlyIncome'] < df_original['MonthlyIncome'].mean() * 0.8: # Example threshold (bottom 20% approx)\n",
        "         interventions.append(\"- Review compensation and benefits.\")\n",
        "\n",
        "    # OverTime is a significant feature\n",
        "    if 'OverTime' in employee_data and employee_data['OverTime'] == 'Yes':\n",
        "        interventions.append(\"- Address workload and consider work-life balance initiatives.\")\n",
        "\n",
        "    # Shorter tenure might be a risk factor\n",
        "    if 'YearsAtCompany' in employee_data and employee_data['YearsAtCompany'] < 3: # Example threshold\n",
        "         interventions.append(\"- Provide mentorship and career development opportunities for newer employees.\")\n",
        "    if 'YearsWithCurrManager' in employee_data and employee_data['YearsWithCurrManager'] < 2: # Example threshold\n",
        "         interventions.append(\"- Facilitate improved relationships with managers and provide support in current role.\")\n",
        "\n",
        "\n",
        "    # Lower satisfaction levels are often linked to attrition\n",
        "    # Assuming satisfaction scales are 1-4, check for values 1 or 2\n",
        "    if 'JobSatisfaction' in employee_data and employee_data['JobSatisfaction'] < 3:\n",
        "        interventions.append(\"- Discuss job role satisfaction and explore opportunities for engagement.\")\n",
        "    if 'EnvironmentSatisfaction' in employee_data and employee_data['EnvironmentSatisfaction'] < 3:\n",
        "        interventions.append(\"- Assess work environment factors.\")\n",
        "    if 'RelationshipSatisfaction' in employee_data and employee_data['RelationshipSatisfaction'] < 3:\n",
        "         interventions.append(\"- Facilitate improved relationships with colleagues or managers.\")\n",
        "    if 'WorkLifeBalance' in employee_data and employee_data['WorkLifeBalance'] < 3:\n",
        "        interventions.append(\"- Support work-life balance through flexible arrangements or workload management.\")\n",
        "\n",
        "    # MaritalStatus_Single was noted as a characteristic of high-risk employees\n",
        "    # if 'MaritalStatus' in employee_data and employee_data['MaritalStatus'] == 'Single': # Removed as requested\n",
        "    #      interventions.append(\"- Offer support networks or community-building activities.\")\n",
        "\n",
        "    # Business Travel Frequency\n",
        "    if 'BusinessTravel' in employee_data and employee_data['BusinessTravel'] == 'Travel_Frequently':\n",
        "         interventions.append(\"- Review business travel frequency and its impact on work-life balance.\")\n",
        "\n",
        "    # Add other relevant checks based on your analysis (e.g., Job Role, Department if they showed high attrition rates)\n",
        "\n",
        "    return interventions\n",
        "\n",
        "\n",
        "# Prediction button\n",
        "if st.button('Predict Attrition and Suggest Interventions'):\n",
        "    # Prepare the input data using the employee number\n",
        "    if df_original is not None and scaler is not None and expected_feature_columns is not None:\n",
        "        input_df_processed, original_employee_data, error_message = prepare_input_data_by_id(\n",
        "            employee_number_input,\n",
        "            df_original,\n",
        "            scaler,\n",
        "            original_numerical_cols,\n",
        "            original_categorical_cols,\n",
        "            expected_feature_columns\n",
        "        )\n",
        "\n",
        "        if error_message:\n",
        "            st.error(error_message)\n",
        "        else:\n",
        "            # Make prediction\n",
        "            # predict_proba returns probabilities for both classes [prob_class_0, prob_class_1]\n",
        "            # We want the probability of attrition (class 1)\n",
        "            prediction_proba = best_rf_model.predict_proba(input_df_processed)[:, 1]\n",
        "\n",
        "            # Display the predicted probability\n",
        "            st.subheader('Prediction Result')\n",
        "            st.write(f'Predicted Attrition Likelihood: **{prediction_proba[0]:.2f}**')\n",
        "\n",
        "            # Interpretation based on probability and suggestion of interventions\n",
        "            if prediction_proba[0] >= 0.5: # Threshold for suggesting interventions\n",
        "                st.warning('Based on the model, this employee is predicted to be at High Risk of Attrition.')\n",
        "                st.write(\"It might be beneficial to look into factors that could be contributing to this risk.\")\n",
        "\n",
        "                # Suggest intervention areas for high-risk employees\n",
        "                st.subheader('Suggested Intervention Areas')\n",
        "                intervention_suggestions = suggest_interventions(original_employee_data, df_original)\n",
        "\n",
        "\n",
        "                if intervention_suggestions:\n",
        "                    for suggestion in intervention_suggestions:\n",
        "                        st.markdown(suggestion)\n",
        "                else:\n",
        "                    st.write(\"No specific intervention areas identified based on current rules for this employee.\")\n",
        "\n",
        "\n",
        "            elif prediction_proba[0] >= 0.3: # Moderate risk (adjust thresholds as needed)\n",
        "                 st.info('This employee is predicted to be at Moderate Risk of Attrition.')\n",
        "                 st.write(\"Monitor this employee's situation. While immediate action may not be necessary, understanding potential factors is helpful.\")\n",
        "                 # Optionally suggest interventions for moderate risk as well, perhaps a less extensive list\n",
        "                 # st.subheader('Potential Areas to Monitor')\n",
        "                 # intervention_suggestions = suggest_interventions(original_employee_data)\n",
        "                 # if intervention_suggestions:\n",
        "                 #     for suggestion in intervention_suggestions:\n",
        "                 #         st.markdown(suggestion)\n",
        "\n",
        "\n",
        "            else: # Low risk\n",
        "                st.success('This employee is predicted to be at Low Risk of Attrition.')\n",
        "                st.write(\"Based on the current information, this employee is likely to stay.\")\n",
        "\n",
        "            # Include a disclaimer\n",
        "            st.write(\"\"\"\n",
        "            *Note: This prediction is based on the trained machine learning model and the input data provided.\n",
        "            It is a probabilistic estimate and may not capture all factors influencing an employee's decision to leave.\n",
        "            Intervention suggestions are based on general patterns and employee characteristics, not a definitive diagnosis.*\n",
        "            \"\"\")\n",
        "    else:\n",
        "        st.error(\"Application not fully loaded. Please ensure model, scaler, and data files are available and try again.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-10-08 15:31:42.042 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.149 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.150 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.153 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.155 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.156 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.157 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.158 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.160 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.162 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.163 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.164 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.164 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.165 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.168 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.170 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.171 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.172 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.173 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.174 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.178 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.179 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.180 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.181 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.183 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-10-08 15:31:42.183 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}